{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,StratifiedShuffleSplit, cross_val_score, train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('MPP_Dataset/Train.csv')\n",
    "test = pd.read_csv('MPP_Dataset/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()\n",
    "\n",
    "train.popularity = train.popularity.replace(5,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    15231\n",
       "3     2166\n",
       "2      472\n",
       "1      323\n",
       "0       16\n",
       "Name: popularity, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.popularity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencoder(train,test,cols=[]):\n",
    "    \n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    #object_cols = catVar1(train) #catVar1 gives desired categorical column and not all object columns\n",
    "    object_cols=cols\n",
    "    print(object_cols)\n",
    "    \n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train[object_cols]))\n",
    "    OH_cols_test = pd.DataFrame(OH_encoder.transform(test[object_cols]))\n",
    "\n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols_train.index = train.index\n",
    "    OH_cols_test.index = test.index\n",
    "\n",
    "    ##hack for restoring columns names just like get dummies\n",
    "    column_name = OH_encoder.get_feature_names(object_cols)\n",
    "    OH_cols_train.columns = column_name\n",
    "    OH_cols_test.columns = column_name\n",
    "    \n",
    "\n",
    "    # Remove desired categorical columns (will replace with one-hot encoding)\n",
    "    num_train = train.drop(object_cols, axis=1)\n",
    "    num_test = test.drop(object_cols, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical/remaining features\n",
    "    OH_train = pd.concat([num_train, OH_cols_train], axis=1)\n",
    "    OH_test = pd.concat([num_test, OH_cols_test], axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    print(OH_train.shape,OH_test.shape)\n",
    "    \n",
    "    \n",
    "    return OH_train,OH_test\n",
    "\n",
    "def targetencoding(train,test,y_train,drop=False,cols=[]):\n",
    "    import category_encoders as ce\n",
    "    # Create the encoder itself\n",
    "    cat_features = cols\n",
    "    print(f'targest emcoding for features {cat_features}')\n",
    "    target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "    \n",
    "\n",
    "    # Fit the encoder using the categorical features and target\n",
    "    target_enc.fit(train[cat_features], y_train)\n",
    "    \n",
    "\n",
    "    # Transform the features, rename the columns with _target suffix, and join to dataframe\n",
    "    traintrgtenc = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "    testtrgtenc = test.join(target_enc.transform(test[cat_features]).add_suffix('_target'))\n",
    "\n",
    "    if drop :\n",
    "        traintrgtenc = traintrgtenc.drop(cat_features, axis =1)\n",
    "        testtrgtenc = testtrgtenc.drop(cat_features, axis =1)\n",
    "\n",
    "    \n",
    "    print(traintrgtenc.shape,testtrgtenc.shape)\n",
    "    \n",
    "    return traintrgtenc,testtrgtenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targest emcoding for features ['Category_1']\n",
      "(18208, 12) (12140, 11)\n",
      "['Category_2']\n",
      "(18208, 13) (12140, 12)\n"
     ]
    }
   ],
   "source": [
    "trainenc,testenc = targetencoding(train,test,train.popularity,drop=True,cols =['Category_1'])\n",
    "trainencohe,testencohe = onehotencoder(trainenc,testenc,cols =['Category_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainenc.drop('popularity',axis=1)\n",
    "Y = trainenc['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ExtraTreesClassifier(warm_start=True,oob_score=False,bootstrap=False ,random_state=786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_rand = {\n",
    "#   'ccp_alpha':  np.linspace(0.1, 1, num=10),\n",
    "#  'criterion': ['gini','entropy'],\n",
    "#  'max_depth':  range(2,25,1),\n",
    "#  'max_features': ['auto','sqrt','log2'],\n",
    "#  'max_leaf_nodes': range(1,100,5),\n",
    "#  'min_samples_leaf': range(1,50,1),\n",
    "#  'min_samples_split': range(1,20,1),\n",
    "#  'n_estimators': range(450,700,25),\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsc = RandomizedSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_distributions=param_rand,\n",
    "#     scoring='neg_log_loss',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose =10)\n",
    "\n",
    "# grid_result = gsc.fit(X, Y)\n",
    "\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best: -0.574999 using {'n_estimators': 475, 'min_samples_split': 15, 'min_samples_leaf': 17, 'max_leaf_nodes': 31, 'max_features': 'log2', 'max_depth': 11, 'criterion': 'gini', 'ccp_alpha': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_rand = {\n",
    "#   'ccp_alpha':  np.linspace(0.1, 1, num=10),\n",
    "#  'criterion': ['gini','entropy'],\n",
    "#  'max_depth':  range(2,25,1),\n",
    "#  'max_features': ['auto','sqrt','log2'],\n",
    "#  'max_leaf_nodes': range(1,100,5),\n",
    "#  'min_samples_leaf': range(1,50,1),\n",
    "#  'min_samples_split': range(1,20,1),\n",
    "#  'n_estimators': range(450,700,25),\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsc = GridSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_grid=param_rand,\n",
    "#     scoring='neg_log_loss',\n",
    "#     n_jobs=-1,\n",
    "#     cv=5,\n",
    "#  verbose =10)\n",
    "\n",
    "# grid_result = gsc.fit(X, Y)\n",
    "\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.svm\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "# FYI: Objective functions can take additional arguments\n",
    "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "def objective(trial):\n",
    "    iris = sklearn.datasets.load_iris()\n",
    "    x, y = iris.data, iris.target\n",
    "\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"SVC\", \"RandomForest\"])\n",
    "    if classifier_name == \"SVC\":\n",
    "        svc_c = trial.suggest_float(\"svc_c\", 1e-10, 1e10, log=True)\n",
    "        classifier_obj = sklearn.svm.SVC(C=svc_c, gamma=\"auto\")\n",
    "    else:\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log=True)\n",
    "        classifier_obj = sklearn.ensemble.RandomForestClassifier(\n",
    "            max_depth=rf_max_depth, n_estimators=10\n",
    "        )\n",
    "\n",
    "    score = sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=-1, cv=3)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/exploring-optuna-a-hyper-parameter-framework-using-logistic-regression-84bd622cd3a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37208834844703553\n",
      "0.37869883476050376\n",
      "0.34930671009905556\n",
      "0.384452551047067\n",
      "0.35798698250871047\n",
      "Mean OOF Score : 0.36850668537247444\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_ = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_,columns=X.columns)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5,shuffle=False ,random_state=42)\n",
    "\n",
    "oof_preds = []\n",
    "oof_scores = []\n",
    "\n",
    "for i , (train_idx,test_idx) in enumerate(folds.split(X,Y)):\n",
    "  train_set = (X.iloc[train_idx],Y.iloc[train_idx])\n",
    "  test_set = (X.iloc[test_idx],Y.iloc[test_idx])\n",
    "\n",
    "  model = ExtraTreesClassifier(n_estimators=500,criterion= 'entropy',warm_start=True,\n",
    "                                oob_score=False,bootstrap=False,max_features='auto',\n",
    "                                random_state=2)\n",
    "\n",
    "  model.fit(*train_set)\n",
    "\n",
    "  preds = model.predict_proba(test_set[0])\n",
    "  score = log_loss(test_set[1],preds)\n",
    "  \n",
    "  oof_pred_fold = model.predict_proba((test)) #scaler.transform\n",
    "  oof_preds.append(oof_pred_fold)\n",
    "\n",
    "  print(score)\n",
    "  oof_scores.append(score)\n",
    "\n",
    "print(\"Mean OOF Score :\",np.mean(oof_scores))\n",
    "final_preds = np.mean(np.array(oof_preds),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.280333</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.116333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.256667</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.100667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044333</td>\n",
       "      <td>0.275333</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.087333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051333</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.585667</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052667</td>\n",
       "      <td>0.248333</td>\n",
       "      <td>0.608667</td>\n",
       "      <td>0.090333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030667</td>\n",
       "      <td>0.320667</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.109667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046333</td>\n",
       "      <td>0.262667</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056333</td>\n",
       "      <td>0.239333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045333</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>0.086667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027667</td>\n",
       "      <td>0.295333</td>\n",
       "      <td>0.558667</td>\n",
       "      <td>0.118333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12140 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4\n",
       "0      0.0  0.058333  0.280333  0.545000  0.116333\n",
       "1      0.0  0.046667  0.256667  0.596000  0.100667\n",
       "2      0.0  0.044333  0.275333  0.593000  0.087333\n",
       "3      0.0  0.051333  0.260000  0.585667  0.103000\n",
       "4      0.0  0.052667  0.248333  0.608667  0.090333\n",
       "...    ...       ...       ...       ...       ...\n",
       "12135  0.0  0.030667  0.320667  0.539000  0.109667\n",
       "12136  0.0  0.046333  0.262667  0.614000  0.077000\n",
       "12137  0.0  0.056333  0.239333  0.608333  0.096000\n",
       "12138  0.0  0.045333  0.246333  0.621667  0.086667\n",
       "12139  0.0  0.027667  0.295333  0.558667  0.118333\n",
       "\n",
       "[12140 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(final_preds)\n",
    "#submission.to_csv(\"submission4.csv\",index=None)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.6844"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
